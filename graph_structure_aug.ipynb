{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adelsuh/cs224_final_project/blob/main/graph_structure_aug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS6ESNtSpN-z"
      },
      "source": [
        "# CS224W Final Project: Tutorial on the Augmentation of Graphs in PyG\n",
        "\n",
        "### Jerry Chan, Jihee Suh, John So"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPsmdGx7UJ4z"
      },
      "source": [
        "### Notebook setup: install PyG + torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "pS2qTpqApIRS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "523e14a9-f618-40a7-caea-286e60984cc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.0+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch_version = str(torch.__version__)\n",
        "if \"2.4.0\" not in torch_version:\n",
        "  !pip install torch==2.4.0 -q\n",
        "print(torch_version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "dies5CJuqmum"
      },
      "outputs": [],
      "source": [
        "scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "!pip install torch-scatter -f $scatter_src -q\n",
        "!pip install torch-sparse -f $sparse_src -q\n",
        "!pip install torch-geometric -q\n",
        "!pip install ogb -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0uIk066oMxUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2236b71c-9c46-4442-a70c-5ee6931e3947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(42)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euGXjAPU1Ss4"
      },
      "source": [
        "### Setting up the dataset and tasks\n",
        "\n",
        "The below code sets up some hyperparameters which will be used in dataloading and training.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model settings\n",
        "hidden_dim = 128 #@param {type: \"integer\"}\n",
        "num_layers = 2 #@param {type: \"integer\"}\n",
        "# Training settings\n",
        "learning_rate = 0.0001 #@param {type: \"number\"}\n",
        "num_epochs = 10 #@param {type: \"integer\"}\n",
        "\n",
        "# Dataloader settings\n",
        "batch_size = 32 #@param {type: \"integer\"}\n",
        "fan_out = 10 #@param {type: \"integer\", hint: \"Used in neighborhood sampling to sample a subgraph\"}\n",
        "dataloader_num_workers = 2 #@param {type: \"integer\"}\n",
        "\n",
        "print(f\"\"\"\n",
        "Running training with the following configuration:\n",
        "   hidden_dim: {hidden_dim}\n",
        "   num_layers: {num_layers}\n",
        "   learning_rate: {learning_rate}\n",
        "   num_epochs: {num_epochs}\n",
        "   batch_size: {batch_size}\n",
        "\"\"\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Eg2APSF7WvSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b02e2099-6fe5-4b0a-80bd-de07df4b74a6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running training with the following configuration:\n",
            "   hidden_dim: 128\n",
            "   num_layers: 2\n",
            "   learning_rate: 0.0001\n",
            "   num_epochs: 10\n",
            "   batch_size: 32\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### About the task: etc. etc.\n",
        "\n",
        "Some generic description about obgn.\n",
        "\n",
        "Run the below block to create the dataset. If this is your first time loading the dataset, it will additionally prompt you to download files.\n",
        "\n",
        "**Note**: this block loads the dataset into RAM each time it is called! So calling this block multiple times will likely consume all of the notebook's RAM. Take caution."
      ],
      "metadata": {
        "id": "fNIrDcPdY9ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ogb.nodeproppred import PygNodePropPredDataset\n",
        "dataset = PygNodePropPredDataset(name='ogbn-products', root='./products/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjEjRXaMZLqZ",
        "outputId": "b73413eb-d6ce-47cb-b10b-a4fc0f5bf4fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ogb/nodeproppred/dataset_pyg.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.data, self.slices = torch.load(self.processed_paths[0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_idx = dataset.get_idx_split()\n",
        "# sample test set to speed up\n",
        "split_idx['test'] = split_idx['test'][:1000]\n",
        "split_idx['valid'] = split_idx['valid'][:1000]\n",
        "\n",
        "print(f\"\"\"\n",
        "Summary of the OBGN Products dataset:\n",
        "  Number of graphs: {len(dataset)}\n",
        "  Number of features: {dataset.num_features}\n",
        "  Number of classes: {dataset.num_classes}\n",
        "  Length of each split:\n",
        "    Training: {len(split_idx['train'])}\n",
        "    Validation: {len(split_idx['valid'])}\n",
        "    Test: {len(split_idx['test'])}\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKdSKWebalo3",
        "outputId": "a6a70846-77a5-4a5e-ddfc-1dd89a9fcad9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary of the OBGN Products dataset:\n",
            "  Number of graphs: 1\n",
            "  Number of features: 100\n",
            "  Number of classes: 47\n",
            "  Length of each split:\n",
            "    Training: 196615\n",
            "    Validation: 1000\n",
            "    Test: 1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's create some dataloaders!\n",
        "\n",
        "todo: write something about neighbor loader. why do we need this?"
      ],
      "metadata": {
        "id": "aUYQHiFYYloB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import NeighborLoader\n",
        "\n",
        "data = dataset[0]\n",
        "train_loader = NeighborLoader(\n",
        "    data,\n",
        "    input_nodes=split_idx['train'],\n",
        "    num_neighbors=[fan_out] * num_layers,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    pin_memory=True,\n",
        "    num_workers=dataloader_num_workers\n",
        ")\n",
        "val_loader = NeighborLoader(\n",
        "    data,\n",
        "    input_nodes=split_idx['valid'],\n",
        "    num_neighbors=[fan_out] * num_layers,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=dataloader_num_workers,\n",
        ")\n",
        "test_loader = NeighborLoader(\n",
        "    data,\n",
        "    input_nodes=split_idx['test'],\n",
        "    num_neighbors=[fan_out] * num_layers,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3loxjdsYkwv",
        "outputId": "d8696d5a-a8c6-4efe-eb58-194e1a776233"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
            "  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0HmhMpxvuxO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "340a1174-29d2-4abe-bc3c-f6808530eefe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example batch:\n",
            "Data(num_nodes=3143, edge_index=[2, 3400], x=[3143, 100], y=[3143, 1], n_id=[3143], e_id=[3400], input_id=[32], batch_size=32)\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "# Print summary data for each split\n",
        "print(f\"Example batch:\")\n",
        "train_batch = next(iter(train_loader))\n",
        "print(train_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRim-oBTUVSe"
      },
      "source": [
        "### Training and Evaluation Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RGBPUxkQ2R7H"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn.models import GraphSAGE\n",
        "\n",
        "input_dim = dataset[0].x.shape[1]\n",
        "\n",
        "def get_model():\n",
        "    class GraphSAGENodeClassification(torch.nn.Module):\n",
        "        def __init__(self, input_dim, hidden_dim, num_layers, num_classes):\n",
        "            super(GraphSAGENodeClassification, self).__init__()\n",
        "            self.graph_sage = GraphSAGE(in_channels = input_dim, hidden_channels = hidden_dim, num_layers=num_layers)\n",
        "            self.cls_head = torch.nn.Sequential(\n",
        "                torch.nn.Dropout(0.1),\n",
        "                torch.nn.ReLU(),\n",
        "                torch.nn.Linear(hidden_dim, num_classes),\n",
        "            )\n",
        "            self.loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "        def forward(self, x, edge_index):\n",
        "            h = self.graph_sage(x, edge_index)\n",
        "            return self.cls_head(h)\n",
        "\n",
        "    model = GraphSAGENodeClassification(input_dim, hidden_dim, num_layers, dataset.num_classes)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    model.to(device)\n",
        "    return model, optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we define a simple training loop and evaluation function:\n"
      ],
      "metadata": {
        "id": "oQk7f7vrcPKR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "KWZejP8NNFlG"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# training process\n",
        "def train_one_epoch(model, dataloader, optimizer, transform=None):\n",
        "    model.train()\n",
        "\n",
        "    # define stats\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    num_examples = 0\n",
        "\n",
        "    for batch in tqdm(dataloader):\n",
        "\n",
        "        # transform batch if needed\n",
        "        batch_size = batch.batch_size\n",
        "        batch = batch.to(device)\n",
        "        if transform is not None:\n",
        "          batch = transform(batch)\n",
        "\n",
        "        # forward pass\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(batch.x, batch.edge_index)[:batch_size]\n",
        "\n",
        "        # backward pass\n",
        "        labels = batch.y[:batch_size].squeeze(-1)\n",
        "        loss = model.loss_fn(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # log stats\n",
        "        total_loss += loss.item() * batch_size\n",
        "        total_correct += logits.argmax(dim=-1).eq(labels).sum().item()\n",
        "        num_examples += batch_size\n",
        "\n",
        "    loss = total_loss / num_examples\n",
        "    acc = total_correct / num_examples\n",
        "    return loss, acc\n",
        "\n",
        "# test process\n",
        "@torch.no_grad()\n",
        "def test(model, dataloader, transform=None, apply_transform=True):\n",
        "    model.eval()\n",
        "\n",
        "    # define states\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    num_examples = 0\n",
        "\n",
        "    for batch in tqdm(dataloader):\n",
        "\n",
        "        # transform batch if needed\n",
        "        batch_size = batch.batch_size\n",
        "        batch = batch.to(device)\n",
        "        if apply_transform and (transform is not None):\n",
        "          batch = transform(batch)\n",
        "\n",
        "        # forward pass\n",
        "        logits = model(batch.x, batch.edge_index)[:batch_size]\n",
        "        labels = batch.y[:batch_size].squeeze(-1)\n",
        "        loss = model.loss_fn(logits, labels)\n",
        "\n",
        "        # log stats\n",
        "        total_loss += loss.item() * batch_size\n",
        "        total_correct += logits.argmax(dim=-1).eq(labels).sum().item()\n",
        "        num_examples += batch_size\n",
        "\n",
        "    loss = total_loss / num_examples\n",
        "    acc = total_correct / num_examples\n",
        "    return loss, acc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train and evaluate out model, call the below function!"
      ],
      "metadata": {
        "id": "7r7qVZHKdIQi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "e41neWDGY_Mw"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, num_epochs, transform=None, apply_transform_at_test=True):\n",
        "    best_val_acc = 0\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        print(f'Epoch: {epoch:02d}')\n",
        "\n",
        "        # training\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, transform)\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {100.0 * train_acc:.2f}%')\n",
        "\n",
        "        # validation\n",
        "        val_loss, val_acc = test(model, val_loader, transform, apply_transform=apply_transform_at_test)\n",
        "        print(f'Val Loss: {val_loss:.4f}, Val Accuracy: {100.0 * val_acc:.2f}%')\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            print('New best validation accuracy, saving model...')\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "\n",
        "    print(f'Best Validation Accuracy: {100.0 * best_val_acc:.2f}%')\n",
        "\n",
        "    # eval best model\n",
        "    model.load_state_dict(torch.load('best_model.pth', weights_only=True))\n",
        "    test_loss, test_final_acc = test(model, test_loader)\n",
        "    print(f'Test Accuracy: {100.0 * test_final_acc:.2f}%')\n",
        "    return {\n",
        "        'test_acc': test_final_acc,\n",
        "        'val_acc': best_val_acc,\n",
        "        'model': model\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To illustrate some example usage, let's run one epoch of our train function."
      ],
      "metadata": {
        "id": "7689hVEydrU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, optimizer = get_model()\n",
        "results = train(model, optimizer, num_epochs=1, transform=None, apply_transform_at_test=False)\n",
        "# print results nicely, similar to how i've printed above\n",
        "for key, value in results.items():\n",
        "    if key == 'model':\n",
        "        continue\n",
        "    print(f'{key}: {value}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s8CzoRYdQnt",
        "outputId": "7ccc4826-d1f0-4248-f599-de2e35594b3a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:31<00:00, 40.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.9142, Train Accuracy: 76.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 29.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.6181, Val Accuracy: 84.10%\n",
            "New best validation accuracy, saving model...\n",
            "Best Validation Accuracy: 84.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:00<00:00, 64.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 67.30%\n",
            "test_acc: 0.673\n",
            "val_acc: 0.841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFw4Vi5o1dPP"
      },
      "source": [
        "## Graph Structure Augmentation\n",
        "\n",
        "Modifying the **struture** of the graph is also a powerful way to improve the performance of GNNs. The performance of GNNs is very much related to the structure of the graph.\n",
        "\n",
        "To better motivate graph structure augmentations, let’s first revisit the core idea of GNNs: message passing. At each layer, nodes aggregate information from their neighbors, gradually building a representation that reflects their local neighborhood structure. In theory, deeper networks should be able to capture broader relationships in the graph, integrating information from distant nodes.\n",
        "\n",
        "- **Over-smoothing**:    Recall that a GNN with $k$ layers aggregates information from each node's $k$-hop neighborhood. Thus, as the network deepens, node representations increasingly mix, and after many layers, nodes tend to converge to very similar representations. This “blending” means that the network struggles to distinguish between nodes, especially in large, densely connected graphs. In extreme cases, the output becomes almost uniform across all nodes, rendering the GNN ineffective for tasks like classification or clustering.\n",
        "\n",
        "- **Global relationships**:    While increasing the receptive field of each node by stacking more GNN layers might seem like a solution, it exacerbates the over-smoothing problem noted above, highlighting the trade-offs between depth and effective information propagation.\n",
        "\n",
        "Graph structure augmentations tackle these challenges head-on by altering the graph’s connectivity, introducing extra nodes and/or edges. to improve the flow of information across the graph, mitigate over-smoothing, and enable GNNs to better capture both local and global patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYXn7Cqm-Ff1"
      },
      "source": [
        "### Half Hop\n",
        "\n",
        "Half-Hop (introduced in [Azabou 2023](https://arxiv.org/abs/2308.09198)) enhances message passing in neural networks by inserting intermediate \"slow nodes\" between connected nodes in a graph. This approach mitigates over-smoothing and improves performance, especially in scenarios where neighboring nodes have different labels. The PyG documentation can be found [here](https://pytorch-geometric.readthedocs.io/en/stable/generated/torch_geometric.transforms.HalfHop.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rKVySq62R7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58e89ac0-ba43-4d93-e8b3-88ac930dde5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with masking probability of 0.1\n",
            "\n",
            "Epoch: 01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:33<00:00, 39.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.9359, Train Accuracy: 76.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 30.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.5973, Val Accuracy: 84.10%\n",
            "New best validation accuracy, saving model...\n",
            "Epoch: 02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:30<00:00, 40.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5623, Train Accuracy: 85.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 30.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.5476, Val Accuracy: 85.50%\n",
            "New best validation accuracy, saving model...\n",
            "Epoch: 03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:34<00:00, 39.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5003, Train Accuracy: 86.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 30.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.5039, Val Accuracy: 86.70%\n",
            "New best validation accuracy, saving model...\n",
            "Epoch: 04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:31<00:00, 40.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4665, Train Accuracy: 87.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 30.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.4782, Val Accuracy: 87.00%\n",
            "New best validation accuracy, saving model...\n",
            "Epoch: 05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:29<00:00, 40.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4389, Train Accuracy: 88.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 28.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.4469, Val Accuracy: 88.30%\n",
            "New best validation accuracy, saving model...\n",
            "Epoch: 06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:30<00:00, 40.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4206, Train Accuracy: 88.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 27.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.4343, Val Accuracy: 88.00%\n",
            "Epoch: 07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:29<00:00, 41.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4054, Train Accuracy: 88.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 30.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.4445, Val Accuracy: 88.00%\n",
            "Epoch: 08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:30<00:00, 40.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3921, Train Accuracy: 89.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 30.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.4255, Val Accuracy: 88.30%\n",
            "Epoch: 09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:29<00:00, 41.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3827, Train Accuracy: 89.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 20.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.3868, Val Accuracy: 89.10%\n",
            "New best validation accuracy, saving model...\n",
            "Epoch: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:37<00:00, 38.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3710, Train Accuracy: 89.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 22.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.3900, Val Accuracy: 89.30%\n",
            "New best validation accuracy, saving model...\n",
            "Best Validation Accuracy: 89.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:00<00:00, 38.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 73.20%\n",
            "Training with masking probability of 0.5\n",
            "\n",
            "Epoch: 01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:39<00:00, 38.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0564, Train Accuracy: 73.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 30.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.6344, Val Accuracy: 82.80%\n",
            "New best validation accuracy, saving model...\n",
            "Epoch: 02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:32<00:00, 40.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6630, Train Accuracy: 82.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 30.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.5484, Val Accuracy: 85.10%\n",
            "New best validation accuracy, saving model...\n",
            "Epoch: 03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:41<00:00, 38.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5886, Train Accuracy: 84.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 30.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.5146, Val Accuracy: 85.40%\n",
            "New best validation accuracy, saving model...\n",
            "Epoch: 04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:31<00:00, 40.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5466, Train Accuracy: 85.11%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 19.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.4855, Val Accuracy: 87.60%\n",
            "New best validation accuracy, saving model...\n",
            "Epoch: 05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:34<00:00, 39.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5147, Train Accuracy: 85.84%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 29.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.4653, Val Accuracy: 87.20%\n",
            "Epoch: 06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:30<00:00, 40.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4910, Train Accuracy: 86.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 30.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.4345, Val Accuracy: 87.80%\n",
            "New best validation accuracy, saving model...\n",
            "Epoch: 07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:33<00:00, 39.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4717, Train Accuracy: 87.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 28.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.4365, Val Accuracy: 88.30%\n",
            "New best validation accuracy, saving model...\n",
            "Epoch: 08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:33<00:00, 39.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4559, Train Accuracy: 87.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 30.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.4226, Val Accuracy: 87.70%\n",
            "Epoch: 09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:34<00:00, 39.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4452, Train Accuracy: 87.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 31.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.3967, Val Accuracy: 88.60%\n",
            "New best validation accuracy, saving model...\n",
            "Epoch: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:36<00:00, 39.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4311, Train Accuracy: 87.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 29.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.4192, Val Accuracy: 88.10%\n",
            "Best Validation Accuracy: 88.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:00<00:00, 53.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 70.90%\n",
            "Training with masking probability of 1.0\n",
            "\n",
            "Epoch: 01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 128/6145 [00:05<02:30, 39.94it/s]"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from torch_geometric.transforms import HalfHop\n",
        "# blend features from src and dest equally (alpha=0.5).\n",
        "# add a virtual node to all edges (p=1)\n",
        "\n",
        "rows = []\n",
        "for hh_prob in [0.1, 0.5, 1.0]:\n",
        "    hh_transform = HalfHop(alpha=0.5, p=hh_prob)\n",
        "    model, optimizer = get_model()\n",
        "    print(f\"Training with edge probability of {hh_prob}\\n\")\n",
        "    result = train(model,\n",
        "                   optimizer,\n",
        "                   num_epochs=num_epochs,\n",
        "                   transform=hh_transform,\n",
        "                   apply_transform_at_test=False)\n",
        "    rows.append({\n",
        "        \"masking_prob\": hh_prob,\n",
        "        \"test_acc\": result['test_acc'],\n",
        "        \"val_acc\": result['val_acc']\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df.to_csv(\"out/masking_prob_results.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkgM8GSD2R7I"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "df.to_csv(\"out/masking_prob_results.csv\")\n",
        "sns.lineplot(data=df, x=\"masking_prob\", y=\"test_acc\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJqO9Ikplx6g"
      },
      "source": [
        "### Virtual Node\n",
        "\n",
        "VirtualNode (introduced in [Gilmer 2017](https://arxiv.org/abs/1704.01212)) appends a virtual node to the given homogeneous graph that is connected to all other nodes. The virtual node serves as a global scratch space that each node both reads from and writes to in every step of message passing. This allows information to travel long distances during the propagation phase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58e89ac0-ba43-4d93-e8b3-88ac930dde5d",
        "id": "HHfjmxWjlx6h"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with masking probability of 0.1\n",
            "\n",
            "Epoch: 01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:33<00:00, 39.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.9359, Train Accuracy: 76.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 30.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.5973, Val Accuracy: 84.10%\n",
            "New best validation accuracy, saving model...\n",
            "Epoch: 02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:30<00:00, 40.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5623, Train Accuracy: 85.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 30.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.5476, Val Accuracy: 85.50%\n",
            "New best validation accuracy, saving model...\n",
            "Epoch: 03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:34<00:00, 39.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5003, Train Accuracy: 86.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 30.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.5039, Val Accuracy: 86.70%\n",
            "New best validation accuracy, saving model...\n",
            "Epoch: 04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:31<00:00, 40.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4665, Train Accuracy: 87.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 30.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.4782, Val Accuracy: 87.00%\n",
            "New best validation accuracy, saving model...\n",
            "Epoch: 05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:29<00:00, 40.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4389, Train Accuracy: 88.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 28.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.4469, Val Accuracy: 88.30%\n",
            "New best validation accuracy, saving model...\n",
            "Epoch: 06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:30<00:00, 40.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4206, Train Accuracy: 88.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 27.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.4343, Val Accuracy: 88.00%\n",
            "Epoch: 07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:29<00:00, 41.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4054, Train Accuracy: 88.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 30.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.4445, Val Accuracy: 88.00%\n",
            "Epoch: 08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:30<00:00, 40.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3921, Train Accuracy: 89.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 30.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.4255, Val Accuracy: 88.30%\n",
            "Epoch: 09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6145/6145 [02:29<00:00, 41.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3827, Train Accuracy: 89.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 20.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.3868, Val Accuracy: 89.10%\n",
            "New best validation accuracy, saving model...\n",
            "Epoch: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 2361/6145 [00:57<01:55, 32.75it/s]"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from torch_geometric.transforms import VirtualNode\n",
        "\n",
        "rows = []\n",
        "\n",
        "vn_transform = VirtualNode()\n",
        "model, optimizer = get_model()\n",
        "print(f\"Training with virtual node\\n\")\n",
        "result = train(model,\n",
        "                optimizer,\n",
        "                num_epochs=num_epochs,\n",
        "                transform=hh_transform,\n",
        "                apply_transform_at_test=False)\n",
        "rows.append({\n",
        "    \"masking_prob\": hh_prob,\n",
        "    \"test_acc\": result['test_acc'],\n",
        "    \"val_acc\": result['val_acc']\n",
        "})\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df.to_csv(\"out/masking_prob_results.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmNAMhe52R7I"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.utils import add_random_edge\n",
        "from functools import partial\n",
        "import pandas as pd\n",
        "\n",
        "def add_random_edges_batch(batch, p):\n",
        "    batch.edge_index, added_edges = add_random_edge(batch.edge_index, p=p)\n",
        "    return batch\n",
        "\n",
        "rows = []\n",
        "for prob in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
        "    model, optimizer = get_model()\n",
        "    print(f\"Training with masking probability of {prob}\\n\")\n",
        "    transform = partial(add_random_edges_batch, p=prob)\n",
        "    result = train(model, optimizer, transform=transform, apply_transform_at_test=False)\n",
        "    rows.append({\n",
        "        \"edge_prob\":prob,\n",
        "        \"test_acc\": result['test_acc'],\n",
        "        \"val_acc\": result['val_acc']\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df.to_csv(\"out/edge_prob_results.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBLiHgQQ2R7I"
      },
      "outputs": [],
      "source": [
        "sns.lineplot(data=df, x=\"edge_prob\", y=\"test_acc\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktRl8GWF2R7I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "graph",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}