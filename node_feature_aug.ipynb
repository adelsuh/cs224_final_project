{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kS6ESNtSpN-z"
   },
   "source": [
    "# CS224W Final Project: Tutorial on the Augmentation of Graphs in PyG\n",
    "\n",
    "### Jerry Chan, Jihee Suh, John So"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation is a widely used technique that leverages existing data to further train a model, improving its performance and generalization. For structured data formats such as images, augmentation methods can be quite straightforward, including operations like cropping, resizing, rotating, and adding noise. These augmentations are useful for reducing overfitting to the training dataset and adding invariance to certain transformations, such as color shifts, different camera models, and even different camera poses. \n",
    "\n",
    "In graphs, where a local spatial area is not quite as evenly defined, a good augmentation scheme is less obvious, but still remains powerful ways to reduce overfitting. Beyond robustness, graph augmentations can address noted issues, including over-smoothing, aggregation schemes, and graph structure learning to create powerful GNNs. \n",
    "\n",
    "In this tutorial, we aim to provide an intuitive explanation to various graph augmentation schemes. PyG provides several tools to manipulate the underlying graph structure and features, as well as dynamically manipulate them during training time. Using PyG, we will walk through setting up different graph learning problems, apply each augmentation scheme, and demonstrate when using each is a good idea.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvHgPTT8qnlm"
   },
   "source": [
    "## Installation and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPsmdGx7UJ4z"
   },
   "source": [
    "### Notebook setup: install PyG + torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pS2qTpqApIRS",
    "outputId": "00dfed58-8148-4f6c-ef0a-45d6ea01cee3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch_version = str(torch.__version__)\n",
    "if \"2.4.0\" not in torch_version:\n",
    "  !pip install torch==2.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tfbYW_of-wcv",
    "outputId": "fd916716-0ad8-46ef-e690-8c40599d078a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dies5CJuqmum",
    "outputId": "d47159ad-84ad-4602-d944-78965967cee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-2.4.0+cu121.html\n",
      "Requirement already satisfied: torch-scatter in /home/adel/.local/lib/python3.8/site-packages (2.1.2+pt24cu121)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-2.4.0+cu121.html\n",
      "Requirement already satisfied: torch-sparse in /home/adel/.local/lib/python3.8/site-packages (0.6.18+pt24cu121)\n",
      "Requirement already satisfied: scipy in /home/adel/.local/lib/python3.8/site-packages (from torch-sparse) (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /home/adel/.local/lib/python3.8/site-packages (from scipy->torch-sparse) (1.23.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch-geometric in /home/adel/.local/lib/python3.8/site-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in /home/adel/.local/lib/python3.8/site-packages (from torch-geometric) (3.10.10)\n",
      "Requirement already satisfied: fsspec in /home/adel/.local/lib/python3.8/site-packages (from torch-geometric) (2022.1.0)\n",
      "Requirement already satisfied: jinja2 in /home/adel/.local/lib/python3.8/site-packages (from torch-geometric) (3.1.3)\n",
      "Requirement already satisfied: numpy in /home/adel/.local/lib/python3.8/site-packages (from torch-geometric) (1.23.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/adel/.local/lib/python3.8/site-packages (from torch-geometric) (5.9.1)\n",
      "Requirement already satisfied: pyparsing in /home/adel/.local/lib/python3.8/site-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: requests in /home/adel/.local/lib/python3.8/site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home/adel/.local/lib/python3.8/site-packages (from torch-geometric) (4.64.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/adel/.local/lib/python3.8/site-packages (from aiohttp->torch-geometric) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/adel/.local/lib/python3.8/site-packages (from aiohttp->torch-geometric) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/adel/.local/lib/python3.8/site-packages (from aiohttp->torch-geometric) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/adel/.local/lib/python3.8/site-packages (from aiohttp->torch-geometric) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/adel/.local/lib/python3.8/site-packages (from aiohttp->torch-geometric) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/adel/.local/lib/python3.8/site-packages (from aiohttp->torch-geometric) (1.15.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/adel/.local/lib/python3.8/site-packages (from aiohttp->torch-geometric) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/adel/.local/lib/python3.8/site-packages (from jinja2->torch-geometric) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/adel/.local/lib/python3.8/site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torch-geometric) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/adel/.local/lib/python3.8/site-packages (from requests->torch-geometric) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torch-geometric) (2019.11.28)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/adel/.local/lib/python3.8/site-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/adel/.local/lib/python3.8/site-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric) (0.2.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ogb in /home/adel/.local/lib/python3.8/site-packages (1.3.6)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/adel/.local/lib/python3.8/site-packages (from ogb) (2.4.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/adel/.local/lib/python3.8/site-packages (from ogb) (1.23.0)\n",
      "Requirement already satisfied: tqdm>=4.29.0 in /home/adel/.local/lib/python3.8/site-packages (from ogb) (4.64.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/adel/.local/lib/python3.8/site-packages (from ogb) (1.1.2)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/adel/.local/lib/python3.8/site-packages (from ogb) (1.4.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from ogb) (1.14.0)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in /home/adel/.local/lib/python3.8/site-packages (from ogb) (1.26.12)\n",
      "Requirement already satisfied: outdated>=0.2.0 in /home/adel/.local/lib/python3.8/site-packages (from ogb) (0.2.2)\n",
      "Requirement already satisfied: setuptools>=44 in /usr/lib/python3/dist-packages (from outdated>=0.2.0->ogb) (45.2.0)\n",
      "Requirement already satisfied: littleutils in /home/adel/.local/lib/python3.8/site-packages (from outdated>=0.2.0->ogb) (0.2.4)\n",
      "Requirement already satisfied: requests in /home/adel/.local/lib/python3.8/site-packages (from outdated>=0.2.0->ogb) (2.32.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/adel/.local/lib/python3.8/site-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/adel/.local/lib/python3.8/site-packages (from pandas>=0.24.0->ogb) (2022.2.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/adel/.local/lib/python3.8/site-packages (from scikit-learn>=0.20.0->ogb) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/adel/.local/lib/python3.8/site-packages (from scikit-learn>=0.20.0->ogb) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/adel/.local/lib/python3.8/site-packages (from scikit-learn>=0.20.0->ogb) (3.1.0)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch>=1.6.0->ogb) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/adel/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/adel/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/adel/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (2.8.6)\n",
      "Requirement already satisfied: jinja2 in /home/adel/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/adel/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (2022.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/adel/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/adel/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/adel/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/adel/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/adel/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/adel/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/adel/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/adel/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/adel/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/adel/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/adel/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/adel/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/adel/.local/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->ogb) (12.6.77)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/adel/.local/lib/python3.8/site-packages (from jinja2->torch>=1.6.0->ogb) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/adel/.local/lib/python3.8/site-packages (from requests->outdated>=0.2.0->ogb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->outdated>=0.2.0->ogb) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->outdated>=0.2.0->ogb) (2019.11.28)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/adel/.local/lib/python3.8/site-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
    "sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
    "!pip install torch-scatter -f $scatter_src\n",
    "!pip install torch-sparse -f $sparse_src\n",
    "!pip install torch-geometric\n",
    "!pip install ogb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "p_CLxHV2M3Wh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch_geometric.nn.models import GraphSAGE\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import to_undirected\n",
    "from torch_geometric.datasets import KarateClub\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "0uIk066oMxUJ",
    "outputId": "51f627bb-fa8f-4908-bae3-75e36d220b20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euGXjAPU1Ss4"
   },
   "source": [
    "### Dataset and Tasks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate the power of graph augmentations, let’s consider a realistic, grounded graph to benchmark on. The Open Graph Benchmark (OGB) provides many such graphs, including ogbn-products and ogbn-arxiv, which we utilize here. [EDIT IF WE USE OTHER DATASETS TOO] Ogbn-products is a graph of ~2.5M nodes and ~62M edges, and represents an Amazon product co-purchasing network. The task here is to predict the category of a product in a multi-class classification setup. Ogbn-arxiv is also a multi-class classification task, but is of smaller scale with ~170K nodes and ~1.2M edges, and represents the citation network between arXiv papers.\n",
    "\n",
    "Both datasets already have their own splits: ogbn-products has the top 8% products in sales rankings as the training set, the next 2% as validation, and the rest as a test set, while ogbn-arxiv train on papers published until 2017, validate on 2018 papers, then test on the rest. We will leverage these splits for an inductive learning setting and see how different augmentations affect generalization.\n",
    "\n",
    "Here, we use ogbn-products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0HmhMpxvuxO0",
    "outputId": "986d7044-1dbd-4923-c96d-5ed8e7e07fc0"
   },
   "outputs": [],
   "source": [
    "def load_dataset(transform=None):\n",
    "    dataset = PygNodePropPredDataset(name='ogbn-products', root='./products/', transform=transform)\n",
    "    print(dataset, flush=True)\n",
    "    data = dataset[0]\n",
    "    print(data, flush=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adel/.local/lib/python3.8/site-packages/ogb/nodeproppred/dataset_pyg.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PygNodePropPredDataset()\n",
      "Data(num_nodes=2449029, edge_index=[2, 123718280], x=[2449029, 100], y=[2449029, 1])\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRim-oBTUVSe"
   },
   "source": [
    "### Training and Evaluation Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep experiments consistent, we will use one network architecture throughout this tutorial. We will use a 2-layer GraphSAGE model followed by dropout, ReLU activation, and a linear layer for the classification head. The GraphSAGE model learns to generate node embeddings by sampling and aggregating features from a node’s neighborhood, and generalizes well to previously unseen nodes. This model can be stacked with multiple layers, iterating the process of sampling and aggregating for each layer. For a simple demonstration, we limit the model to 2 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KWZejP8NNFlG"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, dataloader, transform=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    n = 0\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device)\n",
    "        if transform is not None:\n",
    "            batch = transform(batch)\n",
    "        output = model(batch.x, batch.edge_index)[:batch.batch_size]\n",
    "        y = batch.y[:batch.batch_size].squeeze().to(torch.long)\n",
    "        loss = model.loss_fn(output, y)\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += int(output.argmax(dim=-1).eq(y).sum())\n",
    "        n += batch.batch_size\n",
    "\n",
    "    return total_loss/n, total_correct/n\n",
    "\n",
    "# Test function here\n",
    "@torch.no_grad()\n",
    "def test(model, dataloader, transform=None):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    n = 0\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        batch = batch.to(device)\n",
    "        if transform is not None:\n",
    "            batch = transform(batch)\n",
    "        out = model(batch.x, batch.edge_index)[:batch.batch_size]\n",
    "        y = batch.y[:batch.batch_size].squeeze().to(torch.long)\n",
    "        loss = model.loss_fn(out, y)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += int(out.argmax(dim=-1).eq(y).sum())\n",
    "        n += batch.batch_size\n",
    "\n",
    "    return total_loss/n, total_correct/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IFLmCKpCdEEH",
    "outputId": "d1fc1e9d-efc4-4bc6-9922-05a1e76c76bc"
   },
   "outputs": [],
   "source": [
    "input_dim = dataset[0].x.shape[1]\n",
    "hidden_dim = 128\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "num_layers = 2\n",
    "\n",
    "fan_out = 10\n",
    "num_workers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_dim=input_dim, dataset=dataset):\n",
    "    class GraphSAGENodeClassification(torch.nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dim, num_layers, num_classes):\n",
    "            super(GraphSAGENodeClassification, self).__init__()\n",
    "            self.graph_sage = GraphSAGE(in_channels = input_dim, hidden_channels = hidden_dim, num_layers=num_layers)\n",
    "            self.cls_head = torch.nn.Sequential(\n",
    "                torch.nn.Dropout(0.1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(hidden_dim, num_classes),\n",
    "            )\n",
    "            self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        def forward(self, x, edge_index):\n",
    "            h = self.graph_sage(x, edge_index)\n",
    "            return self.cls_head(h)\n",
    "\n",
    "    model = GraphSAGENodeClassification(input_dim, hidden_dim, num_layers, dataset.num_classes)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.to(device)\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(dataset, split):\n",
    "    data = dataset[0]\n",
    "\n",
    "    return NeighborLoader(\n",
    "        data,\n",
    "        input_nodes=split,\n",
    "        num_neighbors=[fan_out] * num_layers,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=num_workers\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adel/.local/lib/python3.8/site-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
      "  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n"
     ]
    }
   ],
   "source": [
    "split_idx = dataset.get_idx_split()\n",
    "train_loader = get_dataloader(dataset, split_idx['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = get_dataloader(dataset, split_idx['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_dataloader(dataset, split_idx['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(model, optimizer, train_loader, val_loader, test_loader, transform=None):\n",
    "    all_train_acc, all_val_acc, all_test_acc = [], [], []\n",
    "    best_val_ind, best_val_acc = 0, 0\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss, train_acc = train(model, optimizer, train_loader, transform)\n",
    "        val_loss, val_acc = test(model, val_loader, transform)\n",
    "        test_loss, test_acc = test(model, test_loader, transform)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_val_ind = epoch\n",
    "\n",
    "        print(f'Train {train_loss:.4f} ({100.0 * train_acc:.2f}%) | Val {val_loss:.4f} ({100.0 * val_acc:.2f}%) | Test {test_loss:.4f} ({100.0 * test_acc:.2f}%)')\n",
    "\n",
    "        all_train_acc.append(train_acc)\n",
    "        all_val_acc.append(val_acc)\n",
    "        all_test_acc.append(test_acc)\n",
    "    \n",
    "    return {\n",
    "        'all_train_acc': np.array(all_train_acc),\n",
    "        'all_val_acc': np.array(all_val_acc),\n",
    "        'all_test_acc': np.array(all_test_acc),\n",
    "        'best_val_ind': best_val_ind,\n",
    "        'model': model\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/adel/.local/lib/python3.8/site-packages (from seaborn) (1.23.0)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/adel/.local/lib/python3.8/site-packages (from seaborn) (1.4.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/adel/.local/lib/python3.8/site-packages (from seaborn) (3.7.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/adel/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/adel/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/adel/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/adel/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/adel/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/adel/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/adel/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/adel/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/adel/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (6.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/adel/.local/lib/python3.8/site-packages (from pandas>=1.2->seaborn) (2022.2.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/adel/.local/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.14.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, Optional\n",
    "\n",
    "# Set a clean, modern aesthetic\n",
    "plt.style.use('seaborn-v0_8-pastel')\n",
    "sns.set_palette(\"deep\")\n",
    "\n",
    "def plot(x: Optional[np.ndarray] = None,\n",
    "         y: Dict[str, np.ndarray] = dict(),\n",
    "         xlabel: str = \"\",\n",
    "         ylabel: str = \"accuracy\"):\n",
    "\n",
    "  plt.figure(figsize=(6, 4), dpi=300)\n",
    "\n",
    "  for key, value in y.items():\n",
    "    if x is not None:\n",
    "      plt.plot(x, value, label=key)\n",
    "    else:\n",
    "      plt.plot(value, label=key)\n",
    "\n",
    "  plt.grid(True, linestyle='--', linewidth=0.5, color='grey', alpha=0.7)\n",
    "  plt.title('training accuracy', fontsize=16)\n",
    "  if x is not None:\n",
    "    plt.xlabel(xlabel)\n",
    "  plt.ylabel(ylabel)\n",
    "\n",
    "  plt.legend(frameon=True, fancybox=True, framealpha=0.7)\n",
    "  plt.tight_layout()\n",
    "  plt.gca().set_facecolor('none')\n",
    "  plt.gcf().patch.set_alpha(0.0)\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run this setup without any transformations to get a baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 6145/6145 [01:03<00:00, 97.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1229/1229 [00:12<00:00, 101.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 69160/69160 [09:35<00:00, 120.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.0288 (76.68%) | Val 0.0188 (84.67%) | Test 0.0485 (68.50%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 6145/6145 [00:58<00:00, 104.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1229/1229 [00:10<00:00, 115.78it/s]\n",
      " 34%|██████████████████████████                                                  | 23773/69160 [02:58<05:29, 137.82it/s]"
     ]
    }
   ],
   "source": [
    "model, optimizer = get_model()\n",
    "results = benchmark(model, optimizer, train_loader, val_loader, test_loader)\n",
    "\n",
    "to_plot = {\n",
    "    \"train\": results['all_train_acc'],\n",
    "    \"val\": results['all_val_acc'],\n",
    "}\n",
    "\n",
    "plot(y=to_plot, xlabel=\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Feature Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Positional Encoding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Graph Neural Networks (GNNs), unless nodes possess distinguishing features, isomorphic nodes will inevitably share identical embeddings. If the nodes already have meaningful features that uniquely identify them, this is ideal. However, failing this, additional feature augmentations are required. Basing this augmentation on the position of the node in the graph is known as positional encoding, and provides an inductive bias that helps with learning. A simplified example is provided below to illustrate its functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "from pylab import show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create a small random graph to demonstrate on. We set the number of nodes to 10, make a constant feature of 1 for every node, and create 20 random edges. Feel free to adjust the number of nodes and edges if you'd like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "num_nodes = 10\n",
    "simple_x = torch.ones(num_nodes)\n",
    "simple_edge_index = torch.randint(num_nodes, (2, num_nodes*2))\n",
    "simple_data = Data(x=simple_x, edge_index=simple_edge_index, num_nodes=num_nodes)\n",
    "simple_data, simple_data.x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This random graph is visualized below, based on its features. All the nodes are the same color, blue, because we have constant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = to_networkx(simple_data)\n",
    "plt.figure(figsize=(3,3))\n",
    "pos = nx.spring_layout(G)\n",
    "node_color = [simple_data.x[node] for node in G.nodes()]\n",
    "nx.draw(G, pos=pos, cmap=plt.get_cmap('coolwarm'), node_color=node_color)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Walk Positional Encoding (RWPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyG supports two kinds of positional encoding, the first being Random Walk Positional Encoding. As the name implies, this method is based on the random walk diffusion process. Given a hyperparameter `walk_length` and node `v`, we calculate the probability that a random walk originating at `v` will land back on `v` after 1, 2, 3, ..., `walk_length` steps. This becomes a vector of `walk_length` length that we can concatenate to its original feature vector. Note that, since this is based on a random walk, if two nodes have the exact same neighborhood structure, they will still have the same positional encoding. The upside is that if the structures vary, even at a very far distance, this positional encoding will help differentiate them without using quite so many GNN layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_length = 3\n",
    "rwpe = T.AddRandomWalkPE(walk_length=walk_length, attr_name=None)\n",
    "rwpe(simple_data), rwpe(simple_data).x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the changed node features, we map the norm of the feature vector to colors. We can see that some of the nodes have clearly differentiated themselves, as we intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "node_color = [torch.norm(rwpe(simple_data).x[node]) for node in G.nodes()]\n",
    "nx.draw(G, pos=pos, cmap=plt.get_cmap('coolwarm'), node_color=node_color)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian Eigenvector Positional Encoding (LapPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want a positional encoding that will provide stronger uniqueness to each node, we can use the Laplacian Eigenvector Positional Encoding. This takes the first `lappe_k` eigenvectors of the graph's laplacian matrix (where `lappe_k` is a hyperparameter) and adds it to the node feature matrix. This is not only unique, but is distance-sensitive with respect to the Euclidean norm. One thing to be careful of is that since `lappe_k` is the number of eigenvectors to look at, this shouldn't exceed the number of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lappe_k = 3\n",
    "lappe = T.AddLaplacianEigenvectorPE(k=lappe_k, is_undirected=True, attr_name=None)\n",
    "lappe(simple_data), lappe(simple_data).x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we see that the node features have become much more varied. A limitation exists with this method as well, however, and it is that eigenvectors are sign-ambiguous. An eigenvector with the signs flipped is still the eigenvector of the same eigenvalue, and since we don't have a clear way of deciding which one to choose at each time, a model using this PE scheme must learn to be invariant towards the sign flip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "node_color = [np.linalg.norm(lappe(simple_data).x[node]) for node in G.nodes()]\n",
    "nx.draw(G, pos=pos, cmap=plt.get_cmap('coolwarm'), node_color=node_color)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Node Feature Augmentation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll benchmark these methods on ogbn-products. ogbn-products have node features that are already quite distinctive for each feature, so positional encodings don't actually improve the performance by much. But we can still see that it does not hurt performance, and is a stable addition for any dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_length = 4\n",
    "rwpe = T.AddRandomWalkPE(walk_length=walk_length, attr_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer = get_model(input_dim=input_dim+walk_length)\n",
    "results = benchmark(model, optimizer, train_loader, val_loader, test_loader, rwpe)\n",
    "\n",
    "to_plot = {\n",
    "    \"train\": results['all_train_acc'],\n",
    "    \"val\": results['all_val_acc'],\n",
    "}\n",
    "\n",
    "plot(y=to_plot, xlabel=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lappe_k = 4\n",
    "lappe = T.AddLaplacianEigenvectorPE(k=lappe_k, is_undirected=True, attr_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer = get_model(input_dim=input_dim+lappe_k)\n",
    "results = benchmark(model, optimizer, train_loader, val_loader, test_loader, lappe)\n",
    "\n",
    "to_plot = {\n",
    "    \"train\": results['all_train_acc'],\n",
    "    \"val\": results['all_val_acc'],\n",
    "}\n",
    "\n",
    "plot(y=to_plot, xlabel=\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, head over to (link) to see the graph structure transformations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
